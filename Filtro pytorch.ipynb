{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtro pytorch\n",
    "\n",
    "En este trabajo se muestra el funcionamiento de filtros a imágenes 2d utilizados en redes CNN a través de pytorch.\n",
    "\n",
    "Simplemente usaremos el módulo de neural network de pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializamos una matriz como un tensor 3 dimensional de floats que represente una imagen. Esta como podemos ver tiene un `batch size` de 1, 3 `input channels`, 3 de `input height` y 10 de `input width`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3, 10])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_2d_img = torch.tensor([[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]], [[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [\n",
    "                            1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]], [[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]]], dtype=torch.float)\n",
    "input_2d_img = input_2d_img.unsqueeze(0)\n",
    "input_2d_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para los filtros que aplicaremos usaremos `Conv2d` de pytorch la cual nos permite aplicar una convolución 2d con ciertos parámetros a una entrada.\n",
    "\n",
    "Para este primer filtro utilizamos 3 `canales de entrada` **(como los de nuestra imagen)**, utilizamos 1 `canal de salida`, un tamaño de `kernel`de 3 y finalmente un `stride` para la convolución de 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn2d_1: \n",
      "\n",
      "torch.Size([1, 1, 1, 8]) \n",
      "\n",
      "tensor([[[[0.4645, 1.0574, 1.6503, 2.2432, 2.8361, 3.4290, 4.0218, 4.6147]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "cnn2d_1 = nn.Conv2d(in_channels=3, out_channels=1, kernel_size=3, stride=1)\n",
    "print(\"cnn2d_1: \\n\")\n",
    "print(cnn2d_1(input_2d_img).shape, \"\\n\")\n",
    "print(cnn2d_1(input_2d_img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el segundo filtro utilizamos 3 `canales de entrada` **(como los de nuestra imagen)**, utilizamos 1 `canal de salida`, un tamaño de `kernel`de 3 y finalmente un `stride` para la convolución de 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn2d_2: \n",
      "\n",
      "torch.Size([1, 1, 1, 4]) \n",
      "\n",
      "tensor([[[[1.2704, 1.9867, 2.7031, 3.4195]]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "cnn2d_2 = nn.Conv2d(in_channels=3, out_channels=1, kernel_size=3, stride=2)\n",
    "print(\"cnn2d_2: \\n\")\n",
    "print(cnn2d_2(input_2d_img).shape, \"\\n\")\n",
    "print(cnn2d_2(input_2d_img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este tercer filtro utilizamos 3 `canales de entrada` **(como los de nuestra imagen)**, utilizamos 5 `canales de salida`, un tamaño de `kernel`de 3 y finalmente un `stride` para la convolución de 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn2d_4: \n",
      "\n",
      "torch.Size([1, 5, 1, 8]) \n",
      "\n",
      "tensor([[[[ 1.0049,  1.3614,  1.7178,  2.0743,  2.4307,  2.7871,  3.1436,\n",
      "            3.5000]],\n",
      "\n",
      "         [[-0.4538, -0.7888, -1.1237, -1.4586, -1.7936, -2.1285, -2.4635,\n",
      "           -2.7984]],\n",
      "\n",
      "         [[ 1.4862,  2.0866,  2.6870,  3.2873,  3.8877,  4.4880,  5.0884,\n",
      "            5.6888]],\n",
      "\n",
      "         [[-1.8991, -2.4983, -3.0975, -3.6967, -4.2959, -4.8951, -5.4943,\n",
      "           -6.0935]],\n",
      "\n",
      "         [[ 0.9618,  1.3580,  1.7543,  2.1505,  2.5468,  2.9431,  3.3393,\n",
      "            3.7356]]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "cnn2d_4 = nn.Conv2d(in_channels=3, out_channels=5, kernel_size=3, stride=1)\n",
    "print(\"cnn2d_4: \\n\")\n",
    "print(cnn2d_4(input_2d_img).shape, \"\\n\")\n",
    "print(cnn2d_4(input_2d_img))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c8c8126ee7d09036a9be68e2d7485108a9393f31f73f6be4eb368e830a315c41"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('topicos': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
